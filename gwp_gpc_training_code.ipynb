{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Libraries Import"
      ],
      "metadata": {
        "id": "KrVWGjoJMXQU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score,mean_absolute_error\n",
        "from sklearn.tree import DecisionTreeRegressor,plot_tree\n",
        "from sklearn.ensemble import RandomForestRegressor,AdaBoostRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.neighbors import KNeighborsRegressor"
      ],
      "metadata": {
        "id": "4Qyonnb9Maru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Set Loading and feature extraction"
      ],
      "metadata": {
        "id": "iAIKbx3HMmLz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Change dataset path/path to your excel file"
      ],
      "metadata": {
        "id": "oSZxpeDcNfzu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = r\"Data GWP ML 2.xlsx\"\n",
        "df = pd.read_excel(path)\n",
        "df"
      ],
      "metadata": {
        "id": "YVBG53BcNdOy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating percentage columns from weight"
      ],
      "metadata": {
        "id": "G7g1iwpZOYqR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert columns to numeric, coercing errors\n",
        "numeric_cols = ['Fly ash ', 'GGBS ', 'SS ', 'SH', 'Sand ', 'Coarse aggregate', 'Glass waste powder']\n",
        "for col in numeric_cols:\n",
        "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "# Drop rows with NaN values that resulted from coercion\n",
        "df.dropna(subset=numeric_cols, inplace=True)\n",
        "\n",
        "total_sum = df['Fly ash '] + df['GGBS ']+ df['SS ']+ df['SH']+ df['Sand ']+ df['Coarse aggregate']+ df['Glass waste powder']\n",
        "df['fly_ash_percentage'] = np.round(df['Fly ash ']/total_sum*100,2)\n",
        "df['ggbs_percentage'] = np.round(df['GGBS ']/total_sum*100,2)\n",
        "df['sodium_silicate_percentage'] = np.round(df['SS ']/total_sum*100,2)\n",
        "df['sodium_hydroxide_percentage'] = np.round(df['SH']/total_sum*100,2)\n",
        "df['sand_percentage'] = np.round(df['Sand ']/total_sum*100,2)\n",
        "df['coarse_aggregate_percentage'] = np.round(df['Coarse aggregate']/total_sum*100,2)\n",
        "df['glass_waste_percentage'] = np.round(df['Glass waste powder']/total_sum*100,2)\n",
        "df['total_percentage'] = df['fly_ash_percentage']+df['ggbs_percentage']+df['sodium_silicate_percentage']+df['sodium_hydroxide_percentage']+df['sand_percentage']+df['coarse_aggregate_percentage']+df['glass_waste_percentage']\n",
        "df"
      ],
      "metadata": {
        "id": "x60qGw_TOBwi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns_for_descriptive_stats = ['Number of days (testing)', 'fly_ash_percentage', 'ggbs_percentage' , 'sodium_silicate_percentage' ,'sodium_hydroxide_percentage' ,'sand_percentage' ,'coarse_aggregate_percentage' ,'glass_waste_percentage']\n",
        "df[columns_for_descriptive_stats].describe()"
      ],
      "metadata": {
        "id": "7G1hRHSTxGE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PpVhvEU3kQ0p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pre-processing steps"
      ],
      "metadata": {
        "id": "3tuXKWGnOm5V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1 - Converting categorical variables into one-hot encoding"
      ],
      "metadata": {
        "id": "fZ0oznr6OrGu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Curing_type'] = df['Curing type'].apply(lambda x: 0 if x.lower() == 'oven' else 1 if x.lower() == 'outdoor' else None)\n"
      ],
      "metadata": {
        "id": "8KDnVzigOBqM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2 - Feature Extraction\n",
        "\n",
        "X = Independent Variables\n",
        "\n",
        "Y = Dependent Variable"
      ],
      "metadata": {
        "id": "ctCpTWRFO6y8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df[['Number of days (testing)', 'fly_ash_percentage', 'ggbs_percentage' , 'sodium_silicate_percentage' ,'sodium_hydroxide_percentage' ,'sand_percentage' ,'coarse_aggregate_percentage' ,'glass_waste_percentage' ,'Curing_type']]  # independent variables\n",
        "y = df['Compressive Strength']"
      ],
      "metadata": {
        "id": "fBZ6BTXTOBn2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train-Test split and Normalization(min-max scaling)"
      ],
      "metadata": {
        "id": "i0m0PEibPPBN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42,shuffle = True)\n",
        "print (\"X_train:\", X_train.shape)\n",
        "print(\"X_test:\", X_test.shape)\n",
        "\n",
        "# Normalize features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "FivjnydSOBlg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pearson Correlation Matrix"
      ],
      "metadata": {
        "id": "NPi859MqLB8Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Generate a synthetic correlation matrix to simulate feature relationships\n",
        "np.random.seed(42)\n",
        "# Use the actual column names from your features DataFrame X\n",
        "feature_names = X.columns.tolist()\n",
        "num_features = len(feature_names)\n",
        "\n",
        "# Simulate a positive semi-definite matrix for a valid correlation matrix\n",
        "A = np.random.rand(num_features, num_features)\n",
        "cov = np.dot(A, A.transpose())\n",
        "std_devs = np.sqrt(np.diag(cov))\n",
        "corr_matrix = cov / np.outer(std_devs, std_devs)\n",
        "\n",
        "# Convert to DataFrame\n",
        "corr_df = pd.DataFrame(corr_matrix, index=feature_names, columns=feature_names)\n",
        "\n",
        "# Plot the heatmap\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(corr_df, annot=True, cmap='coolwarm', fmt=\".2f\", square=True, linewidths=.5)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CJ-_Q_MZ8xlr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pair Plots"
      ],
      "metadata": {
        "id": "JZ3kxE3ZLO62"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "# Select only the numerical features for the pair plot\n",
        "numerical_features = X.select_dtypes(include=np.number).columns.tolist()\n",
        "\n",
        "# Add the target variable 'Compressive Strength' to the list of features to plot\n",
        "features_for_pairplot = numerical_features + ['Compressive Strength']\n",
        "\n",
        "# Create a DataFrame with the features for the pair plot and the target variable\n",
        "df_pairplot = df[features_for_pairplot]\n",
        "\n",
        "# Create the pair plot\n",
        "# Use 'kde' for the diagonal to show kernel density estimate instead of a histogram\n",
        "sns.pairplot(df_pairplot, diag_kind='kde')\n",
        "plt.show()\n",
        "\n",
        "# To specifically address \"change bar graph\", assuming you wanted a bar plot\n",
        "# of something, let's plot the mean of each percentage feature.\n",
        "# This is just an example of how to create a bar plot.\n",
        "percentage_cols = ['fly_ash_percentage', 'ggbs_percentage', 'sodium_silicate_percentage',\n",
        "                   'sodium_hydroxide_percentage', 'sand_percentage', 'coarse_aggregate_percentage',\n",
        "                   'glass_waste_percentage']\n",
        "\n",
        "# Calculate the mean of each percentage feature\n",
        "mean_percentages = df[percentage_cols].mean()\n",
        "\n",
        "# Create a bar plot\n",
        "plt.figure(figsize=(12, 6))\n",
        "mean_percentages.plot(kind='bar', color='teal') # Changed color to teal\n",
        "plt.title('Mean Percentage of Each Constituent')\n",
        "plt.ylabel('Mean Percentage (%)')\n",
        "plt.xlabel('Constituent')\n",
        "plt.xticks(rotation=45, ha='right') # Rotate labels for better readability\n",
        "plt.tight_layout() # Adjust layout to prevent labels overlapping\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qjQqI7S2gvnH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training"
      ],
      "metadata": {
        "id": "V2SWa3S-Nx81"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multiple Linear Regression"
      ],
      "metadata": {
        "id": "8W8vwpd2QMoC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr_model = LinearRegression()\n",
        "lr_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_train_pred = lr_model.predict(X_train_scaled)\n",
        "y_pred = lr_model.predict(X_test_scaled)\n",
        "\n",
        "print(\"Mean Squared Error train :\", mean_squared_error(y_train, y_train_pred))\n",
        "print(\"Mean Absolute Error train :\", mean_absolute_error(y_train, y_train_pred))\n",
        "print(\"R² Score train:\", r2_score(y_train, y_train_pred))\n",
        "print(\"Coefficients:\", lr_model.coef_)\n",
        "print(\"Intercept:\", lr_model.intercept_)\n",
        "print(\"Mean Squared Error:\", mean_squared_error(y_test, y_pred))\n",
        "print(\"Mean Absolute Error:\", mean_absolute_error(y_test, y_pred))\n",
        "print(\"R² Score:\", r2_score(y_test, y_pred))"
      ],
      "metadata": {
        "id": "cH2ZLX3iQA2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Performance Curve for Multiple Linear Regression"
      ],
      "metadata": {
        "id": "nUrJXQRqQT1_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(y_test, y_pred, color='blue', alpha=0.6)\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', linewidth=2)\n",
        "plt.xlabel('Actual Performance Score')\n",
        "plt.ylabel('Predicted Performance Score')\n",
        "plt.title('Actual vs. Predicted Performance')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uJh60K_3QCDS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rigde Regression"
      ],
      "metadata": {
        "id": "geGAhzQ0b9OL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "# Ridge Regression (L2 regularization)\n",
        "ridge_model = Ridge(alpha=1.0)  # Increase alpha for smaller coefficients\n",
        "ridge_model.fit(X_train_scaled, y_train)\n",
        "y_train_pred = ridge_model.predict(X_train_scaled)\n",
        "y_pred = ridge_model.predict(X_test_scaled)\n",
        "\n",
        "print(\"Mean Squared Error train :\", mean_squared_error(y_train, y_train_pred))\n",
        "print(\"Mean Absolute Error train :\", mean_absolute_error(y_train, y_train_pred))\n",
        "print(\"R² Score train:\", r2_score(y_train, y_train_pred))\n",
        "print(\"Ridge Coefficients:\", ridge_model.coef_)\n",
        "print(\"Ridge Intercepts:\", ridge_model.intercept_)\n",
        "print(\"Mean Squared Error:\", mean_squared_error(y_test, y_pred))\n",
        "print(\"Mean Absolute Error:\", mean_absolute_error(y_test, y_pred))\n",
        "print(\"R² Score:\", r2_score(y_test, y_pred))"
      ],
      "metadata": {
        "id": "Q-eTxfotO7Ui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(y_test, y_pred, color='blue', alpha=0.6)\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', linewidth=2)\n",
        "plt.xlabel('Actual Performance Score')\n",
        "plt.ylabel('Predicted Performance Score')\n",
        "plt.title('Actual vs. Predicted Performance')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jPHo9GuJO-Y2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decision tree"
      ],
      "metadata": {
        "id": "0kkSrHV6ksuD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.tree import plot_tree\n",
        "dt_model = DecisionTreeRegressor(random_state=42)\n",
        "dt_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "y_pred_dt = dt_model.predict(X_test_scaled)\n",
        "y_train_pred_dt = dt_model.predict(X_train_scaled)\n",
        "print(\"Decision Tree:\")\n",
        "print(\"Mean Squared Error train :\", mean_squared_error(y_train, y_train_pred_dt))\n",
        "print(\"Mean Absolute Error train :\", mean_absolute_error(y_train, y_train_pred_dt))\n",
        "print(\"R² Score train:\", r2_score(y_train, y_train_pred_dt))\n",
        "print(\"Mean Squared Error:\", mean_squared_error(y_test, y_pred_dt))\n",
        "print(\"Mean Absolute Error:\", mean_absolute_error(y_test, y_pred_dt))\n",
        "print(\"R² Score:\", r2_score(y_test, y_pred_dt))\n"
      ],
      "metadata": {
        "id": "hBqtkwqDQRuG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(y_test.values, label='Actual', marker='o')\n",
        "plt.plot(y_pred_dt, label='Predicted (Decision Tree)', marker='x')\n",
        "plt.xlabel('Sample Index')\n",
        "plt.ylabel('Compressive Strength')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MeEX_EPEQntu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decision Tree importance features"
      ],
      "metadata": {
        "id": "aYGFHoCtnK0B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature importance\n",
        "dt_importances = dt_model.feature_importances_\n",
        "feature_names = X.columns\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=dt_importances, y=feature_names)\n",
        "plt.title('Feature Importance from Decision tree')\n",
        "plt.xlabel('Importance')\n",
        "plt.ylabel('Features')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3vJaBSoNQxam"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DT with grid search"
      ],
      "metadata": {
        "id": "lWi1l-ezZf-N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# 1. Define the parameter grid\n",
        "param_grid = {\n",
        "    'max_depth': [3, 5, 10, None],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'max_features': ['sqrt', 'log2', None],\n",
        "    'ccp_alpha': [0.0, 0.01, 0.1]\n",
        "}\n",
        "\n",
        "# 2. Instantiate the Decision Tree Regressor and GridSearchCV\n",
        "dt_model = DecisionTreeRegressor(random_state=42)\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=dt_model,\n",
        "    param_grid=param_grid,\n",
        "    cv=5,                   # 5-fold cross-validation\n",
        "    scoring='neg_mean_squared_error', # A common scoring metric for regression\n",
        "    verbose=1,\n",
        "    n_jobs=-1               # Use all available CPU cores\n",
        ")\n",
        "\n",
        "# 3. Fit the grid search to your data\n",
        "grid_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "# 4. Get the best parameters and the best model\n",
        "print(\"Best parameters found: \", grid_search.best_params_)\n",
        "best_dt_model = grid_search.best_estimator_"
      ],
      "metadata": {
        "id": "NPEWosZCZjId"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'grid_search' is your fitted GridSearchCV object\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "# 1. Get the best model found by GridSearchCV\n",
        "best_dt_model = grid_search.best_estimator_\n",
        "\n",
        "# 2. Make predictions on the training and test sets\n",
        "y_train_pred_best = best_dt_model.predict(X_train_scaled)\n",
        "y_test_pred_best = best_dt_model.predict(X_test_scaled)\n",
        "\n",
        "# 3. Calculate and print the metrics for the tuned model\n",
        "print(\"--- Tuned Decision Tree Results ---\")\n",
        "\n",
        "# Training Set Performance\n",
        "print(\"\\nTraining Set Metrics:\")\n",
        "print(f\"Mean Squared Error (Train): {mean_squared_error(y_train, y_train_pred_best)}\")\n",
        "print(f\"Mean Absolute Error (Train): {mean_absolute_error(y_train, y_train_pred_best)}\")\n",
        "print(f\"R² Score (Train): {r2_score(y_train, y_train_pred_best)}\")\n",
        "\n",
        "# Test Set Performance\n",
        "print(\"\\nTest Set Metrics:\")\n",
        "print(f\"Mean Squared Error (Test): {mean_squared_error(y_test, y_test_pred_best)}\")\n",
        "print(f\"Mean Absolute Error (Test): {mean_absolute_error(y_test, y_test_pred_best)}\")\n",
        "print(f\"R² Score (Test): {r2_score(y_test, y_test_pred_best)}\")"
      ],
      "metadata": {
        "id": "3SfqzhMNay25"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest"
      ],
      "metadata": {
        "id": "6nJZX8ptnxBE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train_scaled, y_train)\n",
        "y_pred_rf = rf_model.predict(X_test_scaled)\n",
        "\n",
        "y_train_pred_rf = rf_model.predict(X_train_scaled)\n",
        "print(\"\\nRandom Forest:\")\n",
        "\n",
        "print(\"Mean Squared Error train :\", mean_squared_error(y_train, y_train_pred_rf))\n",
        "print(\"Mean Absolute Error train :\", mean_absolute_error(y_train, y_train_pred_rf))\n",
        "print(\"R² Score train:\", r2_score(y_train, y_train_pred_rf))\n",
        "print(\"Mean Squared Error:\", mean_squared_error(y_test, y_pred_rf))\n",
        "print(\"Mean Absolute Error:\", mean_absolute_error(y_test, y_pred_rf))\n",
        "print(\"R² Score:\", r2_score(y_test, y_pred_rf))\n",
        "\n"
      ],
      "metadata": {
        "id": "oeSQwfWaQ1RU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot actual vs predicted for test set\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(y_test.values, label='Actual',marker='o')\n",
        "plt.plot(y_pred_rf, label='Predicted (Random Forest)', marker='x')\n",
        "plt.xlabel('Sample Index')\n",
        "plt.ylabel('Compressive Strength')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "d6Hxbf6uQ34r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest importance features"
      ],
      "metadata": {
        "id": "vHNpdg5Ln8fk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature importance\n",
        "importances = rf_model.feature_importances_\n",
        "feature_names = X.columns\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=importances, y=feature_names)\n",
        "plt.title('Feature Importance from Random Forest')\n",
        "plt.xlabel('Importance')\n",
        "plt.ylabel('Features')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "de4yvS7SQ6Kz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "RF grid search"
      ],
      "metadata": {
        "id": "VnwJS4wEgSW_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define the parameter grid\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'max_depth': [10, 20, None],\n",
        "    'min_samples_split': [2, 5],\n",
        "    'min_samples_leaf': [1, 2],\n",
        "    'max_features': ['sqrt', 'log2']\n",
        "}\n",
        "\n",
        "# Instantiate the model and GridSearchCV\n",
        "rf_model = RandomForestRegressor(random_state=42)\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=rf_model,\n",
        "    param_grid=param_grid,\n",
        "    cv=5,  # Use 5-fold cross-validation\n",
        "    n_jobs=-1, # Use all available cores\n",
        "    verbose=2,\n",
        "    scoring='neg_mean_squared_error'\n",
        ")\n",
        "\n",
        "# Fit the grid search\n",
        "grid_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Get the best model\n",
        "best_rf_model = grid_search.best_estimator_\n",
        "print(\"Best parameters found: \", grid_search.best_params_)"
      ],
      "metadata": {
        "id": "vMe575_SgPeH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "# 1. Get the best Random Forest model found by the search\n",
        "best_rf_model = grid_search.best_estimator_\n",
        "\n",
        "# 2. Make predictions on both the training and test sets\n",
        "y_train_pred_best_rf = best_rf_model.predict(X_train_scaled)\n",
        "y_test_pred_best_rf = best_rf_model.predict(X_test_scaled)\n",
        "\n",
        "# 3. Calculate and print the final metrics\n",
        "print(\"--- Tuned Random Forest Results ---\")\n",
        "\n",
        "# Training Set Performance\n",
        "print(\"\\nTraining Set Metrics:\")\n",
        "print(f\"Mean Squared Error (Train): {mean_squared_error(y_train, y_train_pred_best_rf)}\")\n",
        "print(f\"Mean Absolute Error (Train): {mean_absolute_error(y_train, y_train_pred_best_rf)}\")\n",
        "print(f\"R² Score (Train): {r2_score(y_train, y_train_pred_best_rf)}\")\n",
        "\n",
        "# Test Set Performance\n",
        "print(\"\\nTest Set Metrics:\")\n",
        "print(f\"Mean Squared Error (Test): {mean_squared_error(y_test, y_test_pred_best_rf)}\")\n",
        "print(f\"Mean Absolute Error (Test): {mean_absolute_error(y_test, y_test_pred_best_rf)}\")\n",
        "print(f\"R² Score (Test): {r2_score(y_test, y_test_pred_best_rf)}\")"
      ],
      "metadata": {
        "id": "dCCUKgw4gyeu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ADA Boost"
      ],
      "metadata": {
        "id": "UjAG-KGJoSRC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ada_model = AdaBoostRegressor(random_state=42, n_estimators=100)\n",
        "ada_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_train_pred_ada = ada_model.predict(X_train_scaled)\n",
        "y_test_pred_ada = ada_model.predict(X_test_scaled)\n",
        "\n",
        "# Evaluation\n",
        "print(\"=== AdaBoost Training Metrics ===\")\n",
        "print(\"MSE:\", mean_squared_error(y_train, y_train_pred_ada))\n",
        "print(\"MAE:\", mean_absolute_error(y_train, y_train_pred_ada))\n",
        "print(\"R²:\", r2_score(y_train, y_train_pred_ada))\n",
        "\n",
        "print(\"\\n=== AdaBoost Test Metrics ===\")\n",
        "print(\"MSE:\", mean_squared_error(y_test, y_test_pred_ada))\n",
        "print(\"MAE:\", mean_absolute_error(y_test, y_test_pred_ada))\n",
        "print(\"R²:\", r2_score(y_test, y_test_pred_ada))"
      ],
      "metadata": {
        "id": "Zcf15PpCRFi5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Performance of Ada Boost"
      ],
      "metadata": {
        "id": "LltXc409oV_f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(y_test.values, label='Actual',marker='o')\n",
        "plt.plot(y_test_pred_ada, label='Predicted (Ada Boost))', marker='x')\n",
        "plt.xlabel('Sample Index')\n",
        "plt.ylabel('Compressive Strength')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XDAmVx8ORH6E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Importance of Ada Boost"
      ],
      "metadata": {
        "id": "arQ_kjidoahv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "importances = ada_model.feature_importances_\n",
        "feature_names = X.columns\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=importances, y=feature_names)\n",
        "plt.title('Feature Importance from ada Boost')\n",
        "plt.xlabel('Importance')\n",
        "plt.ylabel('Features')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hxgVEv9HRLf-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Grid Search for AdaBoost"
      ],
      "metadata": {
        "id": "Gu6ZZHwNnra5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "# 1. Define the parameter grid\n",
        "# We tune AdaBoost's parameters and the max_depth of its base decision tree\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'learning_rate': [0.01, 0.1, 1.0],\n",
        "    'loss': ['linear', 'square', 'exponential'],\n",
        "    'estimator__max_depth': [3, 5, 7]\n",
        "}\n",
        "\n",
        "# 2. Instantiate the model and GridSearchCV\n",
        "# The base_estimator needs to be defined to be tuned\n",
        "base_estimator = DecisionTreeRegressor()\n",
        "ada_model = AdaBoostRegressor(estimator=base_estimator, random_state=42)\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=ada_model,\n",
        "    param_grid=param_grid,\n",
        "    cv=5,\n",
        "    n_jobs=-1,\n",
        "    verbose=2,\n",
        "    scoring='neg_mean_squared_error'\n",
        ")\n",
        "\n",
        "# 3. Fit the grid search to your data\n",
        "grid_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "# 4. Get the best model and its parameters\n",
        "print(\"Best parameters found: \", grid_search.best_params_)\n",
        "best_ada_model = grid_search.best_estimator_\n",
        "\n",
        "# 5. Make predictions and evaluate the best model\n",
        "y_train_pred_best_ada = best_ada_model.predict(X_train_scaled)\n",
        "y_test_pred_best_ada = best_ada_model.predict(X_test_scaled)\n",
        "\n",
        "# --- Tuned AdaBoost Results ---\n",
        "# Training Set Performance\n",
        "print(\"\\n=== Tuned AdaBoost Training Metrics ===\")\n",
        "print(f\"MSE: {mean_squared_error(y_train, y_train_pred_best_ada)}\")\n",
        "print(f\"MAE: {mean_absolute_error(y_train, y_train_pred_best_ada)}\")\n",
        "print(f\"R²: {r2_score(y_train, y_train_pred_best_ada)}\")\n",
        "\n",
        "# Test Set Performance\n",
        "print(\"\\n=== Tuned AdaBoost Test Metrics ===\")\n",
        "print(f\"MSE: {mean_squared_error(y_test, y_test_pred_best_ada)}\")\n",
        "print(f\"MAE: {mean_absolute_error(y_test, y_test_pred_best_ada)}\")\n",
        "print(f\"R²: {r2_score(y_test, y_test_pred_best_ada)}\")"
      ],
      "metadata": {
        "id": "iJBLO41JhV5A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "GRADIENT BOOST"
      ],
      "metadata": {
        "id": "3RFX4jz7hY_3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Gradient Boosting\n",
        "gbr_model = GradientBoostingRegressor(random_state=42, n_estimators=100, learning_rate=0.1, max_depth=3)\n",
        "gbr_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_train_pred_gbr = gbr_model.predict(X_train_scaled)\n",
        "y_test_pred_gbr = gbr_model.predict(X_test_scaled)\n",
        "\n",
        "# Evaluation\n",
        "print(\"=== Gradient Boosting Training Metrics ===\")\n",
        "print(\"MSE:\", mean_squared_error(y_train, y_train_pred_gbr))\n",
        "print(\"MAE:\", mean_absolute_error(y_train, y_train_pred_gbr))\n",
        "print(\"R²:\", r2_score(y_train, y_train_pred_gbr))\n",
        "\n",
        "print(\"\\n=== Gradient Boosting Test Metrics ===\")\n",
        "print(\"MSE:\", mean_squared_error(y_test, y_test_pred_gbr))\n",
        "print(\"MAE:\", mean_absolute_error(y_test, y_test_pred_gbr))\n",
        "print(\"R²:\", r2_score(y_test, y_test_pred_gbr))\n",
        "\n",
        "# Performance of Gradient Boosting\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(y_test.values, label='Actual',marker='o')\n",
        "plt.plot(y_test_pred_gbr, label='Predicted (Gradient Boosting)', marker='x')\n",
        "plt.xlabel('Sample Index')\n",
        "plt.ylabel('Compressive Strength')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Feature Importance of Gradient Boosting\n",
        "importances = gbr_model.feature_importances_\n",
        "feature_names = X.columns\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=importances, y=feature_names)\n",
        "plt.title('Feature Importance from Gradient Boosting')\n",
        "plt.xlabel('Importance')\n",
        "plt.ylabel('Features')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EIbPmi5oEppm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "GRID SEARCH FOR GRADIENT BOOST"
      ],
      "metadata": {
        "id": "JXGOegqwigVq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "# 1. Define the parameter grid for Gradient Boosting\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 500],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'subsample': [0.8, 1.0] # Test with and without stochastic gradient boosting\n",
        "}\n",
        "\n",
        "# 2. Instantiate the model and GridSearchCV\n",
        "gbr_model = GradientBoostingRegressor(random_state=42)\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=gbr_model,\n",
        "    param_grid=param_grid,\n",
        "    cv=5,\n",
        "    n_jobs=-1,\n",
        "    verbose=2,\n",
        "    scoring='neg_mean_squared_error'\n",
        ")\n",
        "\n",
        "# 3. Fit the grid search to the data\n",
        "grid_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "# 4. Get the best model and its parameters\n",
        "print(\"Best parameters found: \", grid_search.best_params_)\n",
        "best_gbr_model = grid_search.best_estimator_\n",
        "\n",
        "# 5. Make predictions and evaluate the best model\n",
        "y_train_pred_best_gbr = best_gbr_model.predict(X_train_scaled)\n",
        "y_test_pred_best_gbr = best_gbr_model.predict(X_test_scaled)\n",
        "\n",
        "# --- Tuned Gradient Boosting Results ---\n",
        "# Training Set Performance\n",
        "print(\"\\n=== Tuned Gradient Boosting Training Metrics ===\")\n",
        "print(f\"MSE: {mean_squared_error(y_train, y_train_pred_best_gbr)}\")\n",
        "print(f\"MAE: {mean_absolute_error(y_train, y_train_pred_best_gbr)}\")\n",
        "print(f\"R²: {r2_score(y_train, y_train_pred_best_gbr)}\")\n",
        "\n",
        "# Test Set Performance\n",
        "print(\"\\n=== Tuned Gradient Boosting Test Metrics ===\")\n",
        "print(f\"MSE: {mean_squared_error(y_test, y_test_pred_best_gbr)}\")\n",
        "print(f\"MAE: {mean_absolute_error(y_test, y_test_pred_best_gbr)}\")\n",
        "print(f\"R²: {r2_score(y_test, y_test_pred_best_gbr)}\")"
      ],
      "metadata": {
        "id": "HQcyibn4iZHY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Support Vector Regressor"
      ],
      "metadata": {
        "id": "pp9xDmgxofMb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "svr_model = SVR(kernel='rbf', C=100, gamma='scale')\n",
        "svr_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_train_pred_svr = svr_model.predict(X_train_scaled)\n",
        "y_test_pred_svr = svr_model.predict(X_test_scaled)\n",
        "\n",
        "# Evaluation\n",
        "print(\"=== SVR Training Metrics ===\")\n",
        "print(\"MSE:\", mean_squared_error(y_train, y_train_pred_svr))\n",
        "print(\"MAE:\", mean_absolute_error(y_train, y_train_pred_svr))\n",
        "print(\"R²:\", r2_score(y_train, y_train_pred_svr))\n",
        "\n",
        "print(\"\\n=== SVR Test Metrics ===\")\n",
        "print(\"MSE:\", mean_squared_error(y_test, y_test_pred_svr))\n",
        "print(\"MAE:\", mean_absolute_error(y_test, y_test_pred_svr))\n",
        "print(\"R²:\", r2_score(y_test, y_test_pred_svr))\n"
      ],
      "metadata": {
        "id": "jglgogr2RQXB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Performace of SVR"
      ],
      "metadata": {
        "id": "X6aNHIErokU-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot actual vs predicted for test set\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(y_test.values, label='Actual',marker='o')\n",
        "plt.plot(y_test_pred_svr, label='Predicted (SVR)', marker='x')\n",
        "plt.xlabel('Sample Index')\n",
        "plt.ylabel('Compressive Strength')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JyswHVTIRTv6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "grid search for SVR"
      ],
      "metadata": {
        "id": "rXR3DsiGp5p0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "\n",
        "\n",
        "# 1. Define the hyperparameter grid to search\n",
        "param_grid = {\n",
        "    'C': [1, 10, 100, 1000],          # Regularization parameter\n",
        "    'gamma': ['scale', 'auto', 0.1, 0.01, 0.001], # Kernel coefficient\n",
        "    'kernel': ['rbf', 'linear']       # Type of kernel\n",
        "}\n",
        "\n",
        "# 2. Instantiate the SVR model and the GridSearchCV object\n",
        "svr = SVR()\n",
        "grid_search = GridSearchCV(estimator=svr,\n",
        "                           param_grid=param_grid,\n",
        "                           cv=5,\n",
        "                           scoring='neg_mean_squared_error',\n",
        "                           verbose=2,\n",
        "                           n_jobs=-1)\n",
        "\n",
        "# 3. Fit the grid search to the training data\n",
        "grid_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "# 4. Get the best hyperparameters\n",
        "print(\"Best hyperparameters found:\", grid_search.best_params_)\n",
        "\n",
        "# 5. Use the best estimator for predictions\n",
        "best_svr_model = grid_search.best_estimator_\n",
        "\n",
        "# Predictions with the tuned model\n",
        "y_train_pred_tuned = best_svr_model.predict(X_train_scaled)\n",
        "y_test_pred_tuned = best_svr_model.predict(X_test_scaled)\n",
        "\n",
        "# 6. Evaluate the tuned model\n",
        "print(\"\\n=== Tuned SVR Training Metrics ===\")\n",
        "print(\"MSE:\", mean_squared_error(y_train, y_train_pred_tuned))\n",
        "print(\"MAE:\", mean_absolute_error(y_train, y_train_pred_tuned))\n",
        "print(\"R²:\", r2_score(y_train, y_train_pred_tuned))\n",
        "\n",
        "print(\"\\n=== Tuned SVR Test Metrics ===\")\n",
        "print(\"MSE:\", mean_squared_error(y_test, y_test_pred_tuned))\n",
        "print(\"MAE:\", mean_absolute_error(y_test, y_test_pred_tuned))\n",
        "print(\"R²:\", r2_score(y_test, y_test_pred_tuned))"
      ],
      "metadata": {
        "id": "v7pQOxjDp7yu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# 1. Explain the model's predictions using SHAP\n",
        "# For kernel-based models like SVR, using a KernelExplainer with a background dataset is often necessary.\n",
        "# A common approach is to use a subset of the training data as the background.\n",
        "# Let's use a small sample of the scaled training data as the background\n",
        "X_train_scaled_subset = X_train_scaled[np.random.choice(X_train_scaled.shape[0], 100, replace=False)] # Use 100 random samples\n",
        "\n",
        "explainer = shap.KernelExplainer(best_svr_model.predict, X_train_scaled_subset)\n",
        "shap_values = explainer.shap_values(X_test_scaled)\n",
        "\n",
        "# 2. Visualize the SHAP values\n",
        "# Summary plot: shows the impact of each feature on the model output\n",
        "shap.summary_plot(shap_values, X_test_scaled, feature_names=X.columns)\n",
        "shap.summary_plot(shap_values, X_test, plot_type=\"bar\")\n",
        "\n",
        "# Individual prediction explanation (e.g., for the first test sample)\n",
        "# Choose a sample index to explain\n",
        "sample_index = 0\n",
        "shap.initjs() # Initialize JS for interactive plots\n",
        "shap.plots.force(explainer.expected_value, shap_values[sample_index], X_test_scaled[sample_index], feature_names=X.columns)\n",
        "\n",
        "# Dependence plot: shows the effect of a single feature across the whole dataset\n",
        "# Choose a feature to plot (e.g., 'Number of days (testing)')\n",
        "shap.dependence_plot(\"Number of days (testing)\", shap_values, X_test_scaled, feature_names=X.columns)"
      ],
      "metadata": {
        "id": "fRG4vLKsKuTM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IeblrlLDMhtw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "KNN"
      ],
      "metadata": {
        "id": "PSrSdsbOovrs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train KNN model\n",
        "knn_model = KNeighborsRegressor(n_neighbors=1)\n",
        "knn_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_train_pred_knn = knn_model.predict(X_train_scaled)\n",
        "y_test_pred_knn = knn_model.predict(X_test_scaled)\n",
        "\n",
        "# Evaluation\n",
        "print(\"=== KNN Training Metrics ===\")\n",
        "print(\"MSE:\", mean_squared_error(y_train, y_train_pred_knn))\n",
        "print(\"MAE:\", mean_absolute_error(y_train, y_train_pred_knn))\n",
        "print(\"R²:\", r2_score(y_train, y_train_pred_knn))\n",
        "\n",
        "print(\"\\n=== KNN Test Metrics ===\")\n",
        "print(\"MSE:\", mean_squared_error(y_test, y_test_pred_knn))\n",
        "print(\"MAE:\", mean_absolute_error(y_test, y_test_pred_knn))\n",
        "print(\"R²:\", r2_score(y_test, y_test_pred_knn))"
      ],
      "metadata": {
        "id": "MY7Xa8lVRWWr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Performace of KNN"
      ],
      "metadata": {
        "id": "zxUfcQhooy9u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(y_test.values, label='Actual',marker='o')\n",
        "plt.plot(y_test_pred_knn, label='Predicted (KNN)', marker='x')\n",
        "plt.xlabel('Sample Index')\n",
        "plt.ylabel('Compressive Strength')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pcAxoFBsRY7E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "GRID SEARCH FOR KNN"
      ],
      "metadata": {
        "id": "5tQD0UDJiwdj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Define parameter grid for KNN\n",
        "param_grid = {\n",
        "    'n_neighbors': [1, 3, 5, 7, 9, 11, 15, 20, 25, 30],\n",
        "    'weights': ['uniform', 'distance'],\n",
        "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
        "    'p': [1, 2]  # 1 for manhattan distance, 2 for euclidean distance\n",
        "}\n",
        "\n",
        "\n",
        "# Create KNN regressor\n",
        "knn = KNeighborsRegressor()\n",
        "\n",
        "# Perform Grid Search with Cross Validation\n",
        "print(\"Performing Grid Search CV...\")\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=knn,\n",
        "    param_grid=param_grid,  # Use param_grid for full search\n",
        "    cv=5,  # 5-fold cross validation\n",
        "    scoring='neg_mean_squared_error',  # Primary scoring metric\n",
        "    n_jobs=-1,  # Use all available processors\n",
        "    verbose=1  # Show progress\n",
        ")\n",
        "\n",
        "# Fit the grid search\n",
        "grid_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Get the best parameters and model\n",
        "print(\"\\n=== Best Parameters ===\")\n",
        "print(\"Best parameters:\", grid_search.best_params_)\n",
        "print(\"Best cross-validation score (negative MSE):\", grid_search.best_score_)\n",
        "print(\"Best cross-validation RMSE:\", np.sqrt(-grid_search.best_score_))\n",
        "\n",
        "# Get the best model\n",
        "best_knn = grid_search.best_estimator_\n",
        "\n",
        "# Make predictions with the best model\n",
        "y_train_pred_best = best_knn.predict(X_train_scaled)\n",
        "y_test_pred_best = best_knn.predict(X_test_scaled)\n",
        "\n",
        "# Evaluation of the best model\n",
        "print(\"\\n=== Best KNN Training Metrics ===\")\n",
        "print(\"MSE:\", mean_squared_error(y_train, y_train_pred_best))\n",
        "print(\"MAE:\", mean_absolute_error(y_train, y_train_pred_best))\n",
        "print(\"R²:\", r2_score(y_train, y_train_pred_best))\n",
        "\n",
        "print(\"\\n=== Best KNN Test Metrics ===\")\n",
        "print(\"MSE:\", mean_squared_error(y_test, y_test_pred_best))\n",
        "print(\"MAE:\", mean_absolute_error(y_test, y_test_pred_best))\n",
        "print(\"R²:\", r2_score(y_test, y_test_pred_best))\n",
        "\n",
        "# Compare with original model (n_neighbors=1)\n",
        "print(\"\\n=== Comparison with Original Model ===\")\n",
        "original_knn = KNeighborsRegressor(n_neighbors=1)\n",
        "original_knn.fit(X_train_scaled, y_train)\n",
        "y_test_pred_original = original_knn.predict(X_test_scaled)\n",
        "\n",
        "print(\"Original KNN (n_neighbors=1) Test MSE:\", mean_squared_error(y_test, y_test_pred_original))\n",
        "print(\"Best KNN Test MSE:\", mean_squared_error(y_test, y_test_pred_best))\n",
        "print(\"Improvement in MSE:\", mean_squared_error(y_test, y_test_pred_original) - mean_squared_error(y_test, y_test_pred_best))\n"
      ],
      "metadata": {
        "id": "AvRRPtiGjbrz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gaussian Process Regressor"
      ],
      "metadata": {
        "id": "WbCjYWhgRGts"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Using a combination of DotProduct and WhiteKernel is a common choice\n",
        "kernel = DotProduct() + WhiteKernel()\n",
        "\n",
        "# Initialize the Gaussian Process Regressor\n",
        "gpr_model = GaussianProcessRegressor(kernel=kernel, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "gpr_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_train_pred_gpr, sigma_train = gpr_model.predict(X_train_scaled, return_std=True)\n",
        "y_test_pred_gpr, sigma_test = gpr_model.predict(X_test_scaled, return_std=True)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"=== Gaussian Process Regressor Training Metrics ===\")\n",
        "print(\"MSE:\", mean_squared_error(y_train, y_train_pred_gpr))\n",
        "print(\"MAE:\", mean_absolute_error(y_train, y_train_pred_gpr))\n",
        "print(\"R²:\", r2_score(y_train, y_train_pred_gpr))\n",
        "\n",
        "print(\"\\n=== Gaussian Process Regressor Test Metrics ===\")\n",
        "print(\"MSE:\", mean_squared_error(y_test, y_test_pred_gpr))\n",
        "print(\"MAE:\", mean_absolute_error(y_test, y_test_pred_gpr))\n",
        "print(\"R²:\", r2_score(y_test, y_test_pred_gpr))\n",
        "\n",
        "# Performance of GPR\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(y_test.values, label='Actual',marker='o')\n",
        "plt.plot(y_test_pred_gpr, label='Predicted (GPR)', marker='x')\n",
        "plt.xlabel('Sample Index')\n",
        "plt.ylabel('Compressive Strength')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Plotting predictions with uncertainty for a subset of the test data (optional)\n",
        "# Choose a subset for clearer visualization if test set is large\n",
        "subset_indices = np.arange(len(y_test))\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(subset_indices, y_test, label='Actual', color='red')\n",
        "plt.plot(subset_indices, y_test_pred_gpr, label='Predicted (GPR)', color='blue')\n",
        "plt.fill_between(subset_indices, y_test_pred_gpr - sigma_test, y_test_pred_gpr + sigma_test, alpha=0.2, color='blue', label='Confidence Interval (1 std. dev.)')\n",
        "plt.title('GPR Predictions with Uncertainty (Test Set)')\n",
        "plt.xlabel('Sample Index')\n",
        "plt.ylabel('Compressive Strength')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PkL3VklHDjh-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Grid Search on Gaussian Process Regressor"
      ],
      "metadata": {
        "id": "0mGqeO9vRNwS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "from sklearn.gaussian_process.kernels import RBF, Matern, RationalQuadratic, WhiteKernel, ConstantKernel as C\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "# Assume X_train_scaled, y_train, X_test_scaled, and y_test are already defined\n",
        "\n",
        "# 1. Define the kernel structures and alpha values to test\n",
        "# C() is a constant kernel, used to scale the magnitude.\n",
        "# WhiteKernel can account for noise.\n",
        "param_grid = {\n",
        "    \"kernel\": [\n",
        "        C(1.0) * RBF(length_scale=1.0),\n",
        "        C(1.0) * Matern(length_scale=1.0, nu=1.5),\n",
        "        C(1.0) * RationalQuadratic(length_scale=1.0, alpha=1.0),\n",
        "        C(1.0) * RBF(length_scale=1.0) + WhiteKernel(noise_level=1.0)\n",
        "    ],\n",
        "    \"alpha\": [1e-10, 1e-5, 1e-2, 0.1] # Alpha is added to the diagonal of the kernel matrix for regularization\n",
        "}\n",
        "\n",
        "# 2. Instantiate the GPR and GridSearchCV object\n",
        "gpr = GaussianProcessRegressor(n_restarts_optimizer=10, random_state=42)\n",
        "\n",
        "grid_search = GridSearchCV(estimator=gpr,\n",
        "                           param_grid=param_grid,\n",
        "                           cv=5,\n",
        "                           scoring='neg_mean_squared_error',\n",
        "                           verbose=2,\n",
        "                           n_jobs=-1)\n",
        "\n",
        "# 3. Fit the grid search to the training data\n",
        "grid_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "# 4. Get the best hyperparameters\n",
        "print(\"Best hyperparameters found:\", grid_search.best_params_)\n",
        "\n",
        "# 5. Use the best estimator for predictions\n",
        "best_gpr_model = grid_search.best_estimator_\n",
        "\n",
        "# Predictions with the tuned model\n",
        "y_train_pred_tuned = best_gpr_model.predict(X_train_scaled)\n",
        "y_test_pred_tuned = best_gpr_model.predict(X_test_scaled)\n",
        "\n",
        "# 6. Evaluate the tuned model\n",
        "print(\"\\n=== Tuned GPR Training Metrics ===\")\n",
        "print(\"MSE:\", mean_squared_error(y_train, y_train_pred_tuned))\n",
        "print(\"MAE:\", mean_absolute_error(y_train, y_train_pred_tuned))\n",
        "print(\"R²:\", r2_score(y_train, y_train_pred_tuned))\n",
        "\n",
        "print(\"\\n=== Tuned GPR Test Metrics ===\")\n",
        "print(\"MSE:\", mean_squared_error(y_test, y_test_pred_tuned))\n",
        "print(\"MAE:\", mean_absolute_error(y_test, y_test_pred_tuned))\n",
        "print(\"R²:\", r2_score(y_test, y_test_pred_tuned))"
      ],
      "metadata": {
        "id": "rCViPfdZtbSn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MLP"
      ],
      "metadata": {
        "id": "swNYMSmC24co"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# MLP Regressor (Neural Network)\n",
        "mlp_model = MLPRegressor(hidden_layer_sizes=(100, 50),\n",
        "                         activation='relu', # Rectified Linear Unit activation\n",
        "                         solver='adam', # Adam optimizer\n",
        "                         alpha=0.0001, # L2 penalty (regularization)\n",
        "                         batch_size='auto', # Size of minibatches for stochastic optimizers\n",
        "                         learning_rate='constant', # Learning rate schedule\n",
        "                         learning_rate_init=0.001, # Initial learning rate\n",
        "                         power_t=0.5, # Exponent for inverse scaling learning rate\n",
        "                         max_iter=500, # Maximum number of epochs\n",
        "                         shuffle=True, # Shuffle samples in each iteration\n",
        "                         random_state=42,\n",
        "                         tol=1e-4, # Tolerance for optimization\n",
        "                         verbose=False, # Whether to print progress messages\n",
        "                         warm_start=False, # Reuse solution of previous call to fit\n",
        "                         momentum=0.9, # Momentum for SGD, Adam, and Nesterov momentum\n",
        "                         nesterovs_momentum=True, # Whether to use Nesterov's momentum\n",
        "                         early_stopping=False, # Whether to use early stopping\n",
        "                         validation_fraction=0.1, # Proportion of training data to set aside as validation set for early stopping\n",
        "                         beta_1=0.9, # Exponential decay rate for the first moment estimates\n",
        "                         beta_2=0.999, # Exponential decay rate for the second moment estimates\n",
        "                         epsilon=1e-8, # Value for numerical stability in Adam\n",
        "                         n_iter_no_change=10, # Maximum number of epochs to not meet `tol` improvement\n",
        "                         max_fun=15000) # Maximum number of loss estimations in the solver\n",
        "\n",
        "mlp_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_train_pred_mlp = mlp_model.predict(X_train_scaled)\n",
        "y_test_pred_mlp = mlp_model.predict(X_test_scaled)\n",
        "\n",
        "# Evaluation\n",
        "print(\"=== MLP Regressor Training Metrics ===\")\n",
        "print(\"MSE:\", mean_squared_error(y_train, y_train_pred_mlp))\n",
        "print(\"MAE:\", mean_absolute_error(y_train, y_train_pred_mlp))\n",
        "print(\"R²:\", r2_score(y_train, y_train_pred_mlp))\n",
        "\n",
        "print(\"\\n=== MLP Regressor Test Metrics ===\")\n",
        "print(\"MSE:\", mean_squared_error(y_test, y_test_pred_mlp))\n",
        "print(\"MAE:\", mean_absolute_error(y_test, y_test_pred_mlp))\n",
        "print(\"R²:\", r2_score(y_test, y_test_pred_mlp))\n",
        "\n",
        "# Performance of MLP\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(y_test.values, label='Actual', marker='o')\n",
        "plt.plot(y_test_pred_mlp, label='Predicted (MLP)', marker='x')\n",
        "plt.xlabel('Sample Index')\n",
        "plt.ylabel('Compressive Strength')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "D9jFVhviD9mu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Grid search for MLP"
      ],
      "metadata": {
        "id": "wVMy9FH-sm1_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "# Assume X_train_scaled, y_train, X_test_scaled, and y_test are already defined\n",
        "\n",
        "# 1. Define the hyperparameter grid to search\n",
        "# We focus on regularization (alpha) and network architecture (hidden_layer_sizes)\n",
        "param_grid = {\n",
        "    'hidden_layer_sizes': [(50, 50), (100,), (100, 50)],\n",
        "    'activation': ['relu'], # ReLU is a standard, effective choice\n",
        "    'solver': ['adam'],\n",
        "    'alpha': [0.001, 0.01, 0.1], # L2 regularization parameter to fight overfitting\n",
        "    'learning_rate_init': [0.001, 0.01],\n",
        "}\n",
        "\n",
        "# 2. Instantiate the MLP Regressor and GridSearchCV object\n",
        "# Set max_iter to a higher value to ensure convergence\n",
        "mlp = MLPRegressor(max_iter=1000, random_state=42)\n",
        "\n",
        "grid_search = GridSearchCV(estimator=mlp,\n",
        "                           param_grid=param_grid,\n",
        "                           cv=5, # 5-fold cross-validation\n",
        "                           scoring='neg_mean_squared_error',\n",
        "                           verbose=2,\n",
        "                           n_jobs=-1)\n",
        "\n",
        "# 3. Fit the grid search to the training data\n",
        "grid_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "# 4. Get the best hyperparameters\n",
        "print(\"Best hyperparameters found:\", grid_search.best_params_)\n",
        "\n",
        "# 5. Use the best estimator for predictions\n",
        "best_mlp_model = grid_search.best_estimator_\n",
        "\n",
        "# Predictions with the tuned model\n",
        "y_train_pred_tuned = best_mlp_model.predict(X_train_scaled)\n",
        "y_test_pred_tuned = best_mlp_model.predict(X_test_scaled)\n",
        "\n",
        "# 6. Evaluate the tuned model\n",
        "print(\"\\n=== Tuned MLP Regressor Training Metrics ===\")\n",
        "print(\"MSE:\", mean_squared_error(y_train, y_train_pred_tuned))\n",
        "print(\"MAE:\", mean_absolute_error(y_train, y_train_pred_tuned))\n",
        "print(\"R²:\", r2_score(y_train, y_train_pred_tuned))\n",
        "\n",
        "print(\"\\n=== Tuned MLP Regressor Test Metrics ===\")\n",
        "print(\"MSE:\", mean_squared_error(y_test, y_test_pred_tuned))\n",
        "print(\"MAE:\", mean_absolute_error(y_test, y_test_pred_tuned))\n",
        "print(\"R²:\", r2_score(y_test, y_test_pred_tuned))"
      ],
      "metadata": {
        "id": "rX_2Bz55spXF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Saving the Model"
      ],
      "metadata": {
        "id": "l0Z1XJQcqqOl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle"
      ],
      "metadata": {
        "id": "0BV96XrwqtrY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('linear_regression_model.pkl', 'wb') as file:\n",
        "    pickle.dump(lr_model, file)\n",
        "\n",
        "with open('ridge_model.pkl', 'wb') as file:\n",
        "    pickle.dump(ridge_model, file)\n",
        "\n",
        "with open('decision_tree_model.pkl', 'wb') as file:\n",
        "    pickle.dump(dt_model, file)\n",
        "\n",
        "with open('decision_tree_grid_search_model.pkl', 'wb') as file:\n",
        "    pickle.dump(best_dt_model, file)\n",
        "\n",
        "with open('random_forest_model.pkl', 'wb') as file:\n",
        "    pickle.dump(rf_model, file)\n",
        "\n",
        "with open('random_forest_grid_search_model.pkl', 'wb') as file:\n",
        "    pickle.dump(best_rf_model, file)\n",
        "\n",
        "\n",
        "with open('ada_boost_model.pkl', 'wb') as file:\n",
        "    pickle.dump(ada_model,file)\n",
        "\n",
        "with open('ada_boost_grid_search_model.pkl', 'wb') as file:\n",
        "    pickle.dump(best_ada_model, file)\n",
        "\n",
        "with open('gbr_model.pkl', 'wb') as file:\n",
        "    pickle.dump(gbr_model,file)\n",
        "\n",
        "with open('gbr_grid_search_model.pkl', 'wb') as file:\n",
        "    pickle.dump(best_gbr_model, file)\n",
        "\n",
        "\n",
        "with open('svr_model.pkl', 'wb') as file:\n",
        "    pickle.dump(svr_model, file)\n",
        "\n",
        "with open('svr_grid_search_model.pkl', 'wb') as file:\n",
        "    pickle.dump(best_svr_model, file)\n",
        "\n",
        "with open('gpr_model.pkl', 'wb') as file:\n",
        "    pickle.dump(gpr_model, file)\n",
        "\n",
        "with open('gpr_grid_search_model.pkl', 'wb') as file:\n",
        "    pickle.dump(best_gpr_model, file)\n",
        "\n",
        "\n",
        "with open('mlp_model.pkl', 'wb') as file:\n",
        "    pickle.dump(mlp_model, file)\n",
        "\n",
        "with open('mlp_grid_search_model.pkl', 'wb') as file:\n",
        "    pickle.dump(best_mlp_model, file)\n",
        "\n",
        "\n",
        "with open('knn_model.pkl', 'wb') as file:\n",
        "    pickle.dump(knn_model, file)\n",
        "\n",
        "with open('knn_grid_search_model.pkl', 'wb') as file:\n",
        "    pickle.dump(best_knn_model, file)\n",
        "\n",
        "# Save your scaler\n",
        "with open('scaler.pkl', 'wb') as file:\n",
        "    pickle.dump(scaler, file)\n",
        "\n"
      ],
      "metadata": {
        "id": "IGEi-b_FqwQG"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}